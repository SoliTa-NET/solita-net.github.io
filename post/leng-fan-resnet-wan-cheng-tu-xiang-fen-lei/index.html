<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>【冷饭】ResNET完成图像分类 | SoliTa</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://solita-net.github.io/favicon.ico?v=1721318729138">
<link rel="stylesheet" href="https://solita-net.github.io/styles/main.css">



<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="这是人工智能作业的实验报告，其中有对ResNET论文原理的叙述。

一、实验内容
A. 使用ResNet完成图像分类
阅读论文：Deep residual learning for image recognition （压缩包中已提供），使..." />
    <meta name="keywords" content="人工智能,实验报告,深度学习" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://solita-net.github.io">
        <img src="https://solita-net.github.io/images/avatar.png?v=1721318729138" class="site-logo">
        <h1 class="site-title">SoliTa</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            标签
          </a>
        
      
        
          <a href="https://solita-net.github.io/post/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      记录学习过程
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://solita-net.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">【冷饭】ResNET完成图像分类</h2>
            <div class="post-date">2024-07-18</div>
            
            <div class="post-content" v-pre>
              <p>这是人工智能作业的实验报告，其中有对ResNET论文原理的叙述。</p>
<!-- more -->
<h2 id="一-实验内容">一、实验内容</h2>
<h3 id="a-使用resnet完成图像分类">A. 使用ResNet完成图像分类</h3>
<p>阅读论文：<strong>Deep residual learning for image recognition</strong> （压缩包中已提供），使用PyTorch手动搭建一个ResNet网络（可使用任意ResNet变体，如ResNet-18, ResNet-34等），完成一个图像分类任务，根据自己的算力情况，完成MNIST或Cifar-10数据集上的图像分类任务，提交实验报告及代码。</p>
<p><em>要求：</em></p>
<ul>
<li>实验报告中包含对论文的理解，为什么ResNet是有效的？</li>
<li>实验报告中包含对核心代码的解释（至少包含数据集的预处理、ResNet的定义）。</li>
<li>实验报告中需要提供损失值以及准确率的收敛曲线。</li>
<li>（可选）实验报告中可以探究不同模型参数对结果的影响。</li>
</ul>
<h2 id="二-实验原理">二、实验原理</h2>
<h3 id="21-论文概述">2.1 论文概述</h3>
<p>ResNet，全称是Residual Net，又称作残差神经网络。</p>
<p>通过阅读论文，可以了解ResNet的大致原理。引用论文中的一段阐述。</p>
<blockquote>
<p>We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions.</p>
</blockquote>
<p>这段论述大意为，我们将层重新表述为学习相对于层输入的<strong>残差函数</strong>，而不是学习无参考的函数。</p>
<p>ResNet的核心思想是引入**“残差连接”<strong>或</strong>“跳跃连接”**（skip connection），即让每一个神经网络层学习残差（Residual）。</p>
<ul>
<li>
<p>在传统的网络层中，我们希望学到某种映射$$H(x)$$（也即学习到一种难以直观理解的函数）</p>
</li>
<li>
<p>而在ResNet中，我们希望学到残差映射$$F(x)=H(x)−x$$，因此$$H(x)=F(x)+x$$。</p>
<p>这样，网络层实际上学习的是输入和输出之间的残差。通过这种方式，可以使得信息更容易在网络中传播，从而缓解梯度消失问题。</p>
</li>
</ul>
<p>为什么需要残差映射？论文中提到的关键问题是为了是<strong>网络退化</strong>（这是一个很奇怪但是就是存在的问题）。</p>
<blockquote>
<p>When deeper networks are able to start converging, a degradation problem has been exposed: with the network depth increasing, accuracy gets saturated (which might be unsurprising) and then degrades rapidly. Unexpectedly, such degradation is not caused by overfitting, and adding more layers to a suitably deep model leads to higher training error, as reported in and thoroughly verified by our experiments.</p>
</blockquote>
<p>对一个朴素网络叠加更多层之后，网络的误差会变大，准确性会下滑。而且令人意外的是，这种退化并不是由过拟合引起的（下面这段论述解释了为什么这个现象不是过拟合引起的）。</p>
<blockquote>
<p>Let us consider a shallower architecture and its deeper counterpart that adds more layers onto it. There exists a solution by construction to the deeper model: the added layers are identity mapping, and the other layers are copied from the learned shallower model. The existence of this constructed solution indicates that a deeper model should produce no higher training error than its shallower counterpart. But experiments show that our current solvers on hand are unable to find solutions that are comparably good or better than the constructed solution (or unable to do so in feasible time).</p>
</blockquote>
<p>如果直观思考的话，往一个神经网络中添加一大堆恒等映射层（就是什么都不做，输出输入相同），网络的准确性是不会改变的。但是现实就是，添加了这些层之后，就出现了网络退化问题。</p>
<p>这没有一个很好的解释，但是问题就存在在这：因为单纯的层数增加，即使这些层就是恒等映射都会导致网络退化。</p>
<p>因此很自然就想到，一个可行的办法是让一些输入直接跳接到后面的层中。</p>
<p>反映到实际方法上，就是直接在一些层的后面加上原始输入。</p>
<figure data-type="image" tabindex="1"><img src="https://solita-net.github.io/post-images/1721310555116.png" alt="" loading="lazy"></figure>
<p>仔细思考，此时中间这两个层经过学习之后，学习到的是什么？</p>
<p>因为我们开始要学习一个映射<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">H(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>，但是现在我们往输出加了输入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>，然后我们整个网络经过训练最后还是会变成<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">H(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>，那么神经网络为了能够收敛，学习到的正是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>−</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">H(x)-x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>。</p>
<h3 id="22-网络架构">2.2 网络架构</h3>
<p>上述的结构可以封装为一个模块，我们称之为<strong>残差模块</strong>。</p>
<p>根据上述论文的图示，我们设想一个模块应该有如下的功能：</p>
<ul>
<li>进行卷积运算、批量归一化和ReLU激活。</li>
<li>将输入直接通过短路连接添加到卷积运算的结果上。</li>
</ul>
<p>ResNET相比起CNN来讲，只是多了数个这样的残差块而已。</p>
<h3 id="23-流程图">2.3 流程图</h3>
<figure data-type="image" tabindex="2"><img src="https://solita-net.github.io/post-images/1721310568974.png" alt="" loading="lazy"></figure>
<p>这也是一个很标准的ResNET18的结构。</p>
<p>为什么明明只有6个层，却叫做ResNET18呢？</p>
<p>因为每个残差层里面是自己定义的。我期望一个残差块里的结构应该如下：</p>
<ul>
<li>卷积层1（第一层）</li>
<li>归一化</li>
<li>激活函数</li>
<li>卷积层2（第二层）</li>
<li>归一化</li>
</ul>
<p>然后，每一个残差层里包含两个残差块，即一个残差层里会包含四个层。</p>
<p>这样就一共有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mo>+</mo><mn>4</mn><mo>∗</mo><mn>4</mn><mo>=</mo><mn>18</mn></mrow><annotation encoding="application/x-tex">2+4*4=18</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">8</span></span></span></span>个层了。</p>
<h2 id="三-代码展示">三、代码展示</h2>
<blockquote>
<p>悲报：由于我的电脑只有CPU没有显卡加速，在写好ResNET18之后尝试跑，跑了20分钟一轮都没跑完的情况下把电脑跑蓝屏了。无奈之下，我只能改用ResNET8，即将四个残差层删减之一个，程序才能勉强跑起来。</p>
</blockquote>
<p>首先，<code>pytorch</code>中没有方便的残差层直接拿过来实现。不过，鉴于残差层本质上是由一个完整的神经层加上最后的短接形成的。因此我们可以自己定义一个类把我们想要的功能整合到一个类中实现。</p>
<h3 id="31-残差块">3.1 残差块</h3>
<pre><code class="language-py">class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = F.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = F.relu(out)
        return out
</code></pre>
<p>这些功能几乎和CNN的功能相同，最后一个<code>out</code>的操作也很容易理解。</p>
<p>这里解释一下，<code>downsample</code>是下采样功能，用来防止后面的层和输出结果对不上。这样就可以免去计算的烦恼。</p>
<h3 id="32-resnet8模块">3.2 ResNet8模块</h3>
<pre><code class="language-py">class ResNet(nn.Module):
    def __init__(self, block, layers, num_classes=10):
        super(ResNet, self).__init__()
        self.in_channels = 64
        self.conv = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self.make_layer(block, 64, layers[0])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(64, num_classes)

    def make_layer(self, block, out_channels, blocks, stride=1):
        downsample = None
        if stride != 1 or self.in_channels != out_channels:
            downsample = nn.Sequential(
                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels),
            )
        layers = []
        layers.append(block(self.in_channels, out_channels, stride, downsample))
        self.in_channels = out_channels
        for _ in range(1, blocks):
            layers.append(block(self.in_channels, out_channels))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.layer1(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x
</code></pre>
<p>其他的函数我们见得多了，但是出现了一个新的模块<code>make_layer()</code>。我们现在来逐个解释其中的含义。</p>
<pre><code class="language-py">downsample = None
if stride != 1 or self.in_channels != out_channels:
    downsample = nn.Sequential(
        nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
        nn.BatchNorm2d(out_channels),
    )
</code></pre>
<ul>
<li>这一步是用来下采样使用的。如果上一层的输出对不上这里的输入的话，我们必须通过中间加一个卷积层和归一化把输出调整成输入能够接受的形式。</li>
</ul>
<pre><code class="language-py">layers = []
layers.append(block(self.in_channels, out_channels, stride, downsample))
self.in_channels = out_channels
for _ in range(1, blocks):
    layers.append(block(self.in_channels, out_channels))
</code></pre>
<ul>
<li><code>layer</code>作为一个列表，存储的是<strong>层</strong>，即我们把每一个层都当作了一个元素存进了数组中。然后我们根据传递参数决定一层里面有几个残差块。</li>
</ul>
<pre><code class="language-py">return nn.Sequential(*layers)
</code></pre>
<ul>
<li>这个函数让这个层列表转换成了<code>pytorch</code>需要的格式。很方便的函数。</li>
</ul>
<h3 id="33-resnet函数">3.3 ResNet函数</h3>
<pre><code class="language-py">def ResNET8(num_classes=10):
    return ResNet(ResidualBlock, [2], num_classes)
</code></pre>
<p>这一步是为了程序更加方便的调用执行。这种写法可以发现，ResidualBlock是可以换成其他函数的。这样的协防让程序充满了可拓展性。</p>
<h3 id="34-训练函数">3.4 训练函数</h3>
<pre><code class="language-py">def train(model, train_loader, criterion, optimizer, num_epochs, epoch_losses_list, epoch_accuracy_list):
    print(&quot;-------START TRAINING-------&quot;)
    print(&quot;num_epochs =&quot;, num_epochs)
    print(&quot;model = ResNET8&quot;)
    for epoch in range(num_epochs):
        print(&quot;--------------&quot;)
        print(&quot;epoch&quot;, epoch+1)
        model.train()
        running_loss = 0.0
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * inputs.size(0)
        epoch_loss = running_loss / len(train_loader.dataset)
        print(f'Finish. Loss: {epoch_loss:.4f}')
        epoch_losses_list.append(epoch_loss)
        evaluate(model, test_loader, criterion, epoch_accuracy_list)
</code></pre>
<p>训练时几乎和CNN的时候一模一样。</p>
<p>不仅如此，接下来的几个函数也几乎都是和CNN相同的，因此不会再作进一步解释。</p>
<h3 id="35-检验函数">3.5 检验函数</h3>
<pre><code class="language-py">def evaluate(model, test_loader, criterion, epoch_accuracy_list):
    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    test_loss = test_loss / len(test_loader.dataset)
    print(f'Test Loss= {test_loss:.4f}, Accuracy= {accuracy:.2f}%')
    epoch_accuracy_list.append(accuracy)
</code></pre>
<h3 id="36-画图函数">3.6 画图函数</h3>
<pre><code class="language-py">def plot_loss(losses):
    &quot;&quot;&quot;
    绘制损失值随 epoch 变化的图。

    参数:
    losses (list of float): 每个 epoch 的损失值平均值的列表。
    &quot;&quot;&quot;
    epochs = range(1, len(losses) + 1)  # 生成 epoch 的序列 [1, 2, 3, ..., len(losses)]
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
    plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号

    plt.figure(figsize=(10, 5))  # 设置图形大小
    plt.plot(epochs, losses, 'b', label='训练loss曲线')  # 绘制损失值曲线，'b'表示蓝色线
    plt.title('loss随epoch变化曲线图')  # 图像标题
    plt.xlabel('Epochs次数')  # x轴标签
    plt.ylabel('Loss大小')  # y轴标签
    plt.legend()  # 显示图例
    plt.grid(True)  # 显示网格
    plt.show()  # 显示图像

def plot_accuracy(accuracy_list):
    &quot;&quot;&quot;
    绘制准确率随 epoch 变化的图。

    参数:
    accuracy_list (list of float)
    &quot;&quot;&quot;
    epochs = range(1, len(accuracy_list) + 1)  
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
    plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号

    plt.figure(figsize=(10, 5))  # 设置图形大小
    plt.plot(epochs, accuracy_list, 'b', label='准确率曲线')  # 绘制损失值曲线，'b'表示蓝色线
    plt.title('准确率随epoch变化曲线图')  # 图像标题
    plt.xlabel('Epochs次数')  # x轴标签
    plt.ylabel('准确率')  # y轴标签
    plt.legend()  # 显示图例
    plt.grid(True)  # 显示网格
    plt.show()  # 显示图像
</code></pre>
<h3 id="37-主函数">3.7 主函数</h3>
<pre><code class="language-python">if __name__=='__main__':
    print(&quot;----------Program START----------&quot;)

    epoch_losses_list = []
    epoch_accuracy_list = []

    model = ResNET8(num_classes=10)
    print(&quot;ResNET8 ready.&quot;)

    transform = transforms.Compose(
        [transforms.RandomHorizontalFlip(),
        transforms.RandomCrop(32, padding=4),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])

    print(&quot;start to download CIFAR-10...&quot;)
    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)
    print(&quot;CIFAR-10 ready.&quot;)

    test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)
    print(&quot;loader ready.&quot;)

    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    num_epochs = 20;
    train(model, train_loader, criterion, optimizer, num_epochs, epoch_losses_list, epoch_accuracy_list)
    print(&quot;--------------&quot;)
    print(&quot;Training Finish.&quot;)
    # 评估模型
    evaluate(model, test_loader, criterion, epoch_accuracy_list)
    plot_loss(epoch_losses_list)
    plot_accuracy(epoch_accuracy_list)
</code></pre>
<h2 id="四-结果展示">四、结果展示</h2>
<p>最后实验代码跑出来的结果如下。</p>
<pre><code>----------Program START----------
ResNET8 ready.
start to download CIFAR-10...
Files already downloaded and verified
CIFAR-10 ready.
Files already downloaded and verified
loader ready.
-------START TRAINING-------
num_epochs = 20
model = ResNET8
--------------
epoch 1
Finish. Loss: 1.4996
Test Loss= 1.4736, Accuracy= 46.91%
--------------
epoch 2
Finish. Loss: 1.2029
Test Loss= 1.3536, Accuracy= 51.32%
--------------
epoch 3
Finish. Loss: 1.0499
Test Loss= 1.0975, Accuracy= 60.77%
--------------
epoch 4
Finish. Loss: 0.9424
Test Loss= 1.0323, Accuracy= 62.77%
--------------
epoch 5
Finish. Loss: 0.8776
Test Loss= 1.1024, Accuracy= 61.99%
--------------
epoch 6
Finish. Loss: 0.8151
Test Loss= 0.8779, Accuracy= 69.67%
--------------
epoch 7
Finish. Loss: 0.7757
Test Loss= 0.8543, Accuracy= 70.06%
--------------
epoch 8
Finish. Loss: 0.7394
Test Loss= 0.8283, Accuracy= 71.33%
--------------
epoch 9
Finish. Loss: 0.7117
Test Loss= 0.8113, Accuracy= 71.74%
--------------
epoch 10
Finish. Loss: 0.6840
Test Loss= 0.8477, Accuracy= 70.78%
--------------
epoch 11
Finish. Loss: 0.6610
Test Loss= 0.7801, Accuracy= 72.98%
--------------
epoch 12
Finish. Loss: 0.6395
Test Loss= 0.7281, Accuracy= 75.32%
--------------
epoch 13
Finish. Loss: 0.6235
Test Loss= 0.6794, Accuracy= 75.95%
--------------
epoch 14
Finish. Loss: 0.6077
Test Loss= 0.6938, Accuracy= 75.80%
--------------
epoch 15
Finish. Loss: 0.5937
Test Loss= 0.7213, Accuracy= 75.36%
--------------
epoch 16
Finish. Loss: 0.5757
Test Loss= 0.6768, Accuracy= 76.34%
--------------
epoch 17
Finish. Loss: 0.5646
Test Loss= 0.6648, Accuracy= 77.30%
--------------
epoch 18
Finish. Loss: 0.5490
Test Loss= 0.6453, Accuracy= 77.94%
--------------
epoch 19
Finish. Loss: 0.5425
Test Loss= 0.6946, Accuracy= 76.63%
--------------
epoch 20
Finish. Loss: 0.5281
Test Loss= 0.6681, Accuracy= 77.64%
--------------
Training Finish.
Test Loss= 0.6695, Accuracy= 77.27%
</code></pre>
<p>绘制出的曲线如下。</p>
<figure data-type="image" tabindex="3"><img src="https://solita-net.github.io/post-images/1721310580443.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="4"><img src="https://solita-net.github.io/post-images/1721310586299.png" alt="" loading="lazy"></figure>
<p>可以看到，即使只有一个残差层，收敛速度也是很不错的，准确率也能飙到四分之三以上。</p>
<p>可惜的是，电脑性能不充足让我没办法做一个标准的<code>ResNET18</code>，效果应该会更佳。</p>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://solita-net.github.io/tag/Tna4xPgjx/" class="tag">
                    人工智能
                  </a>
                
                  <a href="https://solita-net.github.io/tag/qRxZOrS34l/" class="tag">
                    实验报告
                  </a>
                
                  <a href="https://solita-net.github.io/tag/ZfcHCEJmS/" class="tag">
                    深度学习
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://solita-net.github.io/post/shen-du-xue-xi-zhong-qian-ni-he-yu-guo-ni-he-wen-ti/">
                  <h3 class="post-title">
                    深度学习中的欠拟合与过拟合
                  </h3>
                </a>
              </div>
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>


  <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  <script>
    hljs.initHighlightingOnLoad()
  </script>





  </body>
</html>

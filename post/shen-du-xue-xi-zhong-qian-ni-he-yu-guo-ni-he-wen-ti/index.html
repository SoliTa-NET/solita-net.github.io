<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>深度学习中的欠拟合与过拟合 | SoliTa</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://solita-net.github.io/favicon.ico?v=1721318729138">
<link rel="stylesheet" href="https://solita-net.github.io/styles/main.css">



<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="学习时间：2024.07.18
学习来源：花书

1.1 定义
我们训练一个模型是为了期待训练误差能和泛化误差接近。
但是我们如果使用更复杂的模型和更少的样本时，很有可能泛化误差会增大。训练时，我们会对不断降低训练误差，但是很有可能泛化后模..." />
    <meta name="keywords" content="深度学习" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://solita-net.github.io">
        <img src="https://solita-net.github.io/images/avatar.png?v=1721318729138" class="site-logo">
        <h1 class="site-title">SoliTa</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            标签
          </a>
        
      
        
          <a href="https://solita-net.github.io/post/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      记录学习过程
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://solita-net.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">深度学习中的欠拟合与过拟合</h2>
            <div class="post-date">2024-07-18</div>
            
            <div class="post-content" v-pre>
              <p>学习时间：2024.07.18<br>
学习来源：花书</p>
<hr>
<h2 id="11-定义">1.1 定义</h2>
<p>我们训练一个模型是为了期待<strong>训练误差能和泛化误差接近</strong>。</p>
<p>但是我们如果使用更复杂的模型和更少的样本时，很有可能泛化误差会增大。训练时，我们会对不断降低训练误差，但是很有可能泛化后模型表现依然然查。</p>
<ul>
<li>当训练误差和泛化误差都很大的时候，称为<strong>欠拟合</strong>。</li>
<li>当训练误差很小，但是泛化误差很大的时候，称为<strong>过拟合</strong>。</li>
</ul>
<h2 id="12-正则化技术">1.2 正则化技术</h2>
<p>正则化技术使用的前提：当我们拥有尽可能多的高质量数据，我们可以考正则化技术降低过拟合的可能性。</p>
<h2 id="13-权重衰减">1.3 权重衰减</h2>
<p>这是一种广泛使用的正则化技术。</p>
<p>其使用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>范数乘一个超参数作为惩罚值，减在损失函数中，作为模型训练的损失函数。</p>
<ul>
<li>
<p>Q：为什么使用2范数而不是1范数？</p>
<p>A：1范数正则化线性回归称为<strong>套索回归</strong>，1范数带来的惩罚效果是会将权重集中在一小部分特征上而将其他权重清零，称为<strong>特征选择</strong>。而二范数正则化线性回归称为<strong>岭回归</strong>，其惩罚带来的效果是对大参数的压制，从而达到缩小拟合函数的体量的效果。</p>
</li>
</ul>
<h2 id="14-暂退法dropout">1.4 暂退法（Dropout）</h2>
<p>模型中的泛化能力和灵活性中的权衡称为<strong>偏差-方差均衡</strong>。</p>
<p>线性模型的灵活性很差（即具有很高的偏差），但是泛化能力很强，对不同的样本都可以得出相似的结果（即方差很小）。而神经网络是另一个极端，其具有极高灵活性的同时很有可能产生非常严重的过拟合（如果训练数据质量很差的话）。</p>
<p>我们期待“好”的预测模型能在未知的数据上有很好的表现。</p>
<p>而在经典泛化理论中，<strong>为了缩小训练和测试性能之间的差距，应该以简单的模型为目标。</strong></p>
<p>这里有一个已证明的结果：**具有输入噪声的训练等价于Tikhonov正则化 **。</p>
<p>因此可以在训练中对多层感知机施加噪声来达到增强平滑性的效果。</p>
<p>称为<strong>暂退法</strong>。</p>
<p>暂退法有效的一种直观理解是，过拟合的原因在于每一层依赖于前一层的激活值。使用暂退法施加噪声的时候，就会破坏这种依赖。</p>
<p>注入噪声的一种思路是杳然每一层的期望值等于没有噪声时的值。意味着注入噪声需要具有无偏性。</p>
<p>有两种实现</p>
<ul>
<li>一种是<strong>注入期望为0的高斯噪声</strong>。</li>
<li>另一种方法是直接<strong>训练时随机屏蔽某些层的输出</strong>（暂退法名称的由来）。</li>
</ul>
<p>如果要在代码中实现一个<code>dropout</code>层，一种好的方法是先生成一串和输入数量一样的列表，然后比较其和传入参数的大小，小于这个参数就屏蔽该层输出。</p>
<pre><code class="language-py">def dropout_layer(X, dropout):
    assert 0 &lt;= dropout &lt;= 1
    # 在本情况中，所有元素都被丢弃
    if dropout == 1:
        return torch.zeros_like(X)
    # 在本情况中，所有元素都被保留
    if dropout == 0:
        return X
    mask = (torch.rand(X.shape) &gt; dropout).float()
    return mask * X / (1.0 - dropout)
</code></pre>
<p>其中最后两行代码的含义如下。</p>
<ul>
<li>
<p><code>torch.rand(X.shape)</code>：生成一个与输入张量<code>X</code>形状相同的张量，每个元素都是介于0到1之间的均匀分布的随机数。</p>
</li>
<li>
<p><code>&gt; dropout</code>：生成一个布尔张量，其中元素值大于<code>dropout</code>的元素为True，否则为False。</p>
</li>
<li>
<p><code>.float()</code>：将布尔张量转换为浮点数张量，其中True变为1.0，False变为0.0。</p>
</li>
<li>
<p><code>mask * X</code>：将掩码<code>mask</code>与输入张量<code>X</code>逐元素相乘，这相当于随机将输入张量<code>X</code>中的部分元素设为0（即“丢弃”这些元素）。</p>
</li>
<li>
<p><code>/ (1.0 - dropout)</code>：对丢弃后的张量进行缩放，以保持输入张量的期望值不变。由于<code>(1.0 - dropout)</code>是剩余元素的比例，因此通过除以这个值，可以使得输出张量的期望值与未应用dropout前的期望值一致。</p>
</li>
</ul>
<p>（当然也可以直接调Dropout这个高级API里有的函数）</p>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://solita-net.github.io/tag/ZfcHCEJmS/" class="tag">
                    深度学习
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://solita-net.github.io/post/ju-zhen-qiu-dao/">
                  <h3 class="post-title">
                    矩阵求导
                  </h3>
                </a>
              </div>
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>


  <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  <script>
    hljs.initHighlightingOnLoad()
  </script>





  </body>
</html>
